{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Multi-Couches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprentissage MLP et quelques exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the OR logical function\n",
      "(0, array([ 0.,  0.]), '0.00')\n",
      "(expected 0.00)\n",
      "(1, array([ 1.,  0.]), '0.98')\n",
      "(expected 1.00)\n",
      "(2, array([ 0.,  1.]), '0.98')\n",
      "(expected 1.00)\n",
      "(3, array([ 1.,  1.]), '1.00')\n",
      "(expected 1.00)\n",
      "\n",
      "Learning the AND logical function\n",
      "(0, array([ 0.,  0.]), '-0.01')\n",
      "(expected 0.00)\n",
      "(1, array([ 1.,  0.]), '0.01')\n",
      "(expected 0.00)\n",
      "(2, array([ 0.,  1.]), '0.00')\n",
      "(expected 0.00)\n",
      "(3, array([ 1.,  1.]), '0.92')\n",
      "(expected 1.00)\n",
      "\n",
      "Learning the XOR logical function\n",
      "(0, array([ 0.,  0.]), '0.03')\n",
      "(expected 0.00)\n",
      "(1, array([ 1.,  0.]), '0.93')\n",
      "(expected 1.00)\n",
      "(2, array([ 0.,  1.]), '0.94')\n",
      "(expected 1.00)\n",
      "(3, array([ 1.,  1.]), '0.03')\n",
      "(expected 0.00)\n",
      "\n",
      "Learning the sin function\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -----------------------------------------------------------------------------\n",
    "# Multi-layer perceptron\n",
    "# Copyright (C) 2011  Nicolas P. Rougier\n",
    "#\n",
    "# Distributed under the terms of the BSD License.\n",
    "# -----------------------------------------------------------------------------\n",
    "# This is an implementation of the multi-layer perceptron with retropropagation\n",
    "# learning.\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "def sigmoid(x):\n",
    "    ''' Sigmoid like function using tanh '''\n",
    "    return np.tanh(x)\n",
    " \n",
    "def dsigmoid(x):\n",
    "    ''' Derivative of sigmoid above '''\n",
    "    return 1.0-x**2\n",
    " \n",
    "class MLP:\n",
    "    ''' Multi-layer perceptron class. '''\n",
    " \n",
    "    def __init__(self, *args):\n",
    "        ''' Initialization of the perceptron with given sizes.  '''\n",
    " \n",
    "        self.shape = args\n",
    "        n = len(args)\n",
    " \n",
    "        # Build layers\n",
    "        self.layers = []\n",
    "        # Input layer (+1 unit for bias)\n",
    "        self.layers.append(np.ones(self.shape[0]+1))\n",
    "        # Hidden layer(s) + output layer\n",
    "        for i in range(1,n):\n",
    "            self.layers.append(np.ones(self.shape[i]))\n",
    " \n",
    "        # Build weights matrix (randomly between -0.25 and +0.25)\n",
    "        self.weights = []\n",
    "        for i in range(n-1):\n",
    "            self.weights.append(np.zeros((self.layers[i].size,\n",
    "                                         self.layers[i+1].size)))\n",
    " \n",
    "        # dw will hold last change in weights (for momentum)\n",
    "        self.dw = [0,]*len(self.weights)\n",
    " \n",
    "        # Reset weights\n",
    "        self.reset()\n",
    " \n",
    "    def reset(self):\n",
    "        ''' Reset weights '''\n",
    " \n",
    "        for i in range(len(self.weights)):\n",
    "            Z = np.random.random((self.layers[i].size,self.layers[i+1].size))\n",
    "            self.weights[i][...] = (2*Z-1)*0.25\n",
    " \n",
    "    def propagate_forward(self, data):\n",
    "        ''' Propagate data from input layer to output layer. '''\n",
    " \n",
    "        # Set input layer\n",
    "        self.layers[0][0:-1] = data\n",
    " \n",
    "        # Propagate from layer 0 to layer n-1 using sigmoid as activation function\n",
    "        for i in range(1,len(self.shape)):\n",
    "            # Propagate activity\n",
    "            self.layers[i][...] = sigmoid(np.dot(self.layers[i-1],self.weights[i-1]))\n",
    " \n",
    "        # Return output\n",
    "        return self.layers[-1]\n",
    " \n",
    " \n",
    "    def propagate_backward(self, target, lrate=0.1, momentum=0.1):\n",
    "        ''' Back propagate error related to target using lrate. '''\n",
    " \n",
    "        deltas = []\n",
    " \n",
    "        # Compute error on output layer\n",
    "        error = target - self.layers[-1]\n",
    "        delta = error*dsigmoid(self.layers[-1])\n",
    "        deltas.append(delta)\n",
    " \n",
    "        # Compute error on hidden layers\n",
    "        for i in range(len(self.shape)-2,0,-1):\n",
    "            delta = np.dot(deltas[0],self.weights[i].T)*dsigmoid(self.layers[i])\n",
    "            deltas.insert(0,delta)\n",
    "            \n",
    "        # Update weights\n",
    "        for i in range(len(self.weights)):\n",
    "            layer = np.atleast_2d(self.layers[i])\n",
    "            delta = np.atleast_2d(deltas[i])\n",
    "            dw = np.dot(layer.T,delta)\n",
    "            self.weights[i] += lrate*dw + momentum*self.dw[i]\n",
    "            self.dw[i] = dw\n",
    " \n",
    "        # Return error\n",
    "        return (error**2).sum()\n",
    " \n",
    " \n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    " \n",
    "    def learn(network,samples, epochs=2500, lrate=.1, momentum=0.1):\n",
    "        # Train \n",
    "        for i in range(epochs):\n",
    "            n = np.random.randint(samples.size)\n",
    "            network.propagate_forward( samples['input'][n] )\n",
    "            network.propagate_backward( samples['output'][n], lrate, momentum )\n",
    "        # Test\n",
    "        for i in range(samples.size):\n",
    "            o = network.propagate_forward( samples['input'][i] )\n",
    "            print (i, samples['input'][i], '%.2f' % o[0],)\n",
    "            print ('(expected %.2f)' % samples['output'][i])\n",
    "        print\n",
    " \n",
    "    network = MLP(2,2,1)\n",
    "    samples = np.zeros(4, dtype=[('input',  float, 2), ('output', float, 1)])\n",
    " \n",
    "    # Example 1 : OR logical function\n",
    "    # -------------------------------------------------------------------------\n",
    "    print (\"Learning the OR logical function\")\n",
    "    network.reset()\n",
    "    samples[0] = (0,0), 0\n",
    "    samples[1] = (1,0), 1\n",
    "    samples[2] = (0,1), 1\n",
    "    samples[3] = (1,1), 1\n",
    "    learn(network, samples)\n",
    " \n",
    "    # Example 2 : AND logical function\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"Learning the AND logical function\")\n",
    "    network.reset()\n",
    "    samples[0] = (0,0), 0\n",
    "    samples[1] = (1,0), 0\n",
    "    samples[2] = (0,1), 0\n",
    "    samples[3] = (1,1), 1\n",
    "    learn(network, samples)\n",
    " \n",
    "    # Example 3 : XOR logical function\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"Learning the XOR logical function\")\n",
    "    network.reset()\n",
    "    samples[0] = (0,0), 0\n",
    "    samples[1] = (1,0), 1\n",
    "    samples[2] = (0,1), 1\n",
    "    samples[3] = (1,1), 0\n",
    "    learn(network, samples)\n",
    " \n",
    "    # Example 4 : Learning sin(x)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"Learning the sin function\")\n",
    "    network = MLP(1,3,1)\n",
    "    \n",
    "    \n",
    "    samples = np.zeros(500, dtype=[('x',  float, 1), ('y', float, 1)])\n",
    "    samples['x'] = np.linspace(0,1,500)\n",
    "    samples['y'] = np.sin(samples['x']*np.pi)\n",
    "    for i in range(10000):\n",
    "        n = np.random.randint(samples.size)\n",
    "        network.propagate_forward(samples['x'][n])\n",
    "        network.propagate_backward(samples['y'][n])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    # Draw real function\n",
    "    x,y = samples['x'],samples['y']\n",
    "    plt.plot(x,y,color='b',lw=1)\n",
    "    # Draw network approximated function\n",
    "    for i in range(samples.shape[0]):\n",
    "        y[i] = network.propagate_forward(x[i])\n",
    "    plt.plot(x,y,color='r',lw=3)\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import *\n",
    "import sklearn as sk\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import TP2_MLP as mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : Cr√©er un ensemble de points avec bruit gaussien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "\n",
    "def f_sin(X) :\n",
    "    Y = np.zeros((X.size, 1))\n",
    "    for i in range(X.size) :\n",
    "        #Y[i] = X[i]*np.sin(X[i])\n",
    "        Y[i] = np.sin(X[i])\n",
    "    return Y\n",
    "\n",
    "\n",
    "X = np.array(range(0,20))/2\n",
    "Y = np.sin(X)\n",
    "\n",
    "Y = Y + np.random.normal(0, 0.2, 20)\n",
    "\n",
    "figure(1)\n",
    "plot(X,Y)\n",
    "scatter(X,Y)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 : Apprendre avec MLP et tracer les courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import TP2_MLP as mlp\n",
    "mlp = mlp.MLP(1,3,1)\n",
    "\n",
    "for i in range(1000):\n",
    "    n = np.random.randint(X.size)\n",
    "    mlp.propagate_forward(X[n])\n",
    "    mlp.propagate_backward(Y[n])\n",
    "\n",
    "\n",
    "figure(2)\n",
    "\n",
    "# Points d'apprentissage\n",
    "scatter(X,Y)\n",
    "# Courbe r√©elle : Blue\n",
    "plot(X,Y,color='b',lw=1)\n",
    "# Courbe estim√©e : Red\n",
    "Y_approx = np.zeros(20)\n",
    "for i in range(Y.shape[0]):\n",
    "    Y_approx[i] = mlp.propagate_forward(Y[i])\n",
    "plot(X,Y_approx,color='r',lw=3)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 : Charger les donn√©es Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "#print iris.data\n",
    "#print iris.feature_names\n",
    "#print iris.target_names\n",
    "#print iris.target_names[iris.target]\n",
    "\n",
    "print(iris.target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Binariser les num√©ros de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Solution 1 : Utiliser deux neurones de sortie : 0 -> 00, 1 -> 01, 2 -> 10\n",
    "\n",
    "target_bin_1 = np.zeros([np.size(iris.target), 2])\n",
    "for i in range(iris.target.shape[0]):\n",
    "    if iris.target[i] == 0 :\n",
    "        target_bin_1[i][0] = 0\n",
    "        target_bin_1[i][1] = 0\n",
    "    elif iris.target[i] == 1 :\n",
    "        target_bin_1[i][0] = 0\n",
    "        target_bin_1[i][1] = 1\n",
    "    elif iris.target[i] == 2 :\n",
    "        target_bin_1[i][0] = 1\n",
    "        target_bin_1[i][1] = 0\n",
    "        \n",
    "print(target_bin_1)\n",
    "## Solution 2 : Utiliser trois neurones de sortie : 0 -> 100, 1 -> 010, 2 -> 001\n",
    "\n",
    "target_bin_2 = np.zeros([np.size(iris.target), 3])\n",
    "for i in range(iris.target.shape[0]):\n",
    "    if iris.target[i] == 0 :\n",
    "        target_bin_2[i][0] = 1\n",
    "        target_bin_2[i][1] = 0\n",
    "        target_bin_2[i][2] = 0\n",
    "    elif iris.target[i] == 1 :\n",
    "        target_bin_2[i][0] = 0\n",
    "        target_bin_2[i][1] = 1\n",
    "        target_bin_2[i][2] = 0\n",
    "    elif iris.target[i] == 2 :\n",
    "        target_bin_2[i][0] = 0\n",
    "        target_bin_2[i][1] = 0\n",
    "        target_bin_2[i][2] = 1\n",
    "        \n",
    "print(target_bin_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 : MLP sur les donn√©es Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import TP2_MLP as mlp\n",
    "\n",
    "mlp = mlp.MLP(4,2,2)\n",
    "\n",
    "for i in range(100):\n",
    "    n = np.random.randint(iris.data.shape[0])\n",
    "    mlp.propagate_forward(iris.data[n])\n",
    "    mlp.propagate_backward(target_bin_1[n])\n",
    "\n",
    "\n",
    "# Points d'apprentissage\n",
    "\n",
    "IrisACP = PCA(n_components=2).fit(iris.data).transform(iris.data)\n",
    "\n",
    "figure(33)\n",
    "# Points d'apprentissage\n",
    "scatter(IrisACP[:,0],IrisACP[:,1])\n",
    "\n",
    "# Courbe estim√©e : Red\n",
    "Iris_approx = np.zeros([150,2])\n",
    "\n",
    "for i in range(iris.data.shape[0]):\n",
    "    Iris_approx[i] = mlp.propagate_forward(iris.data[i])\n",
    "    \n",
    "plot(irisNorm,Iris_approx[:,1],color='r',lw=3)\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 : Normaliser les donn√©es Iris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(iris.data[:,0])\n",
    "np.mean(iris.data[:,1])\n",
    "np.mean(iris.data[:,2])\n",
    "np.mean(iris.data[:,3])\n",
    "\n",
    "irisNorm = np.zeros(iris.data.shape)\n",
    "irisNorm[:,0] = (iris.data[:,0] - np.mean(iris.data[:,0]))/np.std(iris.data[:,0])\n",
    "irisNorm[:,1] = (iris.data[:,1] - np.mean(iris.data[:,1]))/np.std(iris.data[:,1])\n",
    "irisNorm[:,2] = (iris.data[:,2] - np.mean(iris.data[:,2]))/np.std(iris.data[:,2])\n",
    "irisNorm[:,3] = (iris.data[:,3] - np.mean(iris.data[:,3]))/np.std(iris.data[:,3])\n",
    "\n",
    "\n",
    "import TP2_MLP as mlp\n",
    "\n",
    "mlp = mlp.MLP(4,2,2)\n",
    "\n",
    "for i in range(100):\n",
    "    n = np.random.randint(irisNorm.shape[0])\n",
    "    mlp.propagate_forward(irisNorm[n])\n",
    "    mlp.propagate_backward(target_bin_1[n])\n",
    "\n",
    "\n",
    "# Points d'apprentissage\n",
    "\n",
    "IrisNormACP = PCA(n_components=2).fit(irisNorm).transform(irisNorm)\n",
    "\n",
    "figure(34)\n",
    "# Points d'apprentissage\n",
    "scatter(IrisNormACP[:,0],IrisNormACP[:,1])\n",
    "\n",
    "# Courbe estim√©e : Red\n",
    "IrisNorm_approx = np.zeros([150,2])\n",
    "\n",
    "for i in range(irisNorm.shape[0]):\n",
    "    IrisNorm_approx[i] = mlp.propagate_forward(irisNorm[i])\n",
    "    \n",
    "plot(irisNorm,IrisNorm_approx[:,1],color='r',lw=3)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 : MLP avec la deuxi√®me m√©thode de binarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import TP2_MLP as mlp\n",
    "\n",
    "mlp = mlp.MLP(4,2,3)\n",
    "\n",
    "for i in range(100):\n",
    "    n = np.random.randint(irisNorm.shape[0])\n",
    "    mlp.propagate_forward(irisNorm[n])\n",
    "    mlp.propagate_backward(target_bin_2[n])\n",
    "\n",
    "\n",
    "# Points d'apprentissage\n",
    "\n",
    "IrisNormACP = PCA(n_components=2).fit(irisNorm).transform(irisNorm)\n",
    "\n",
    "figure(35)\n",
    "# Points d'apprentissage\n",
    "scatter(IrisNormACP[:,0],IrisNormACP[:,1])\n",
    "\n",
    "# Courbe estim√©e : Red\n",
    "IrisNorm_approx = np.zeros([150,3])\n",
    "\n",
    "for i in range(irisNorm.shape[0]):\n",
    "    IrisNorm_approx[i] = mlp.propagate_forward(irisNorm[i])\n",
    "    \n",
    "plot(irisNorm,IrisNorm_approx[:,1],color='r',lw=3)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
